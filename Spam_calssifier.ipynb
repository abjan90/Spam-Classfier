{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "d43534dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import urllib.request \n",
    "import tarfile\n",
    "\n",
    "DOWNLOAD_ROOT = \"https://spamassassin.apache.org/old/publiccorpus/\"\n",
    "HAM_URL = DOWNLOAD_ROOT + \"20030228_easy_ham.tar.bz2\"\n",
    "SPAM_URL = DOWNLOAD_ROOT + \"20030228_spam.tar.bz2\"\n",
    "SPAM_PATH = os.path.join(\"datasets\" , \"spam\") #It will create a path datasets/spam\n",
    "\n",
    "#Fetched the emails\n",
    "def fetch_spam_data(spam_url = SPAM_URL , spam_path = SPAM_PATH):\n",
    "    if not os.path.isdir(spam_path):\n",
    "        os.makedirs(spam_path)\n",
    "    for file_name , urls in ((\"ham.tar.bz2\" , HAM_URL) , (\"spam.tar.bz2\" , SPAM_URL)):\n",
    "        path = os.path.join(spam_path , file_name) #It will create a path datasets/spam/file_name \n",
    "        if not os.path.isfile(path):\n",
    "            urllib.request.urlretrieve( urls , path) #This will download the file and then store it in the path\n",
    "        tar_bz2_file = tarfile.open(path) #The downloaded fie will be in the format of the .tar so we need tarfile\n",
    "        tar_bz2_file.extractall(spam_path) #Then it will extract the file\n",
    "        tar_bz2_file.close() \n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "4d56ee98",
   "metadata": {},
   "outputs": [],
   "source": [
    "fetch_spam_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "c363dfbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Loaded the email\n",
    "HAM_DIR = os.path.join(SPAM_PATH , \"easy_ham\") #datasets\\spam\\easy_ham\n",
    "SPAM_DIR = os.path.join(SPAM_PATH , \"spam\") #'datasets\\\\spam\\\\spam'\n",
    "\n",
    "ham_filenames = [name for name in sorted(os.listdir(HAM_DIR)) if len(name) > 20]\n",
    "spam_filenames = [name for name in sorted(os.listdir(SPAM_DIR)) if len(name) > 20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "26299285",
   "metadata": {},
   "outputs": [],
   "source": [
    "import email\n",
    "import email.policy \n",
    "\n",
    "def load_email(is_spam , filename , spam_path = SPAM_PATH): \n",
    "    directory = \"spam\" if is_spam else \"easy_ham\" #esley chahi kun email read bhanera select garcha\n",
    "\n",
    "    with open  (os.path.join(spam_path , directory , filename) , \"rb\") as f:   # open .. as f allows to read the email and close when its done as rb-> read in bianry\n",
    "        return email.parser.BytesParser(policy = email.policy.default).parse(f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "675431c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "ham_emails = [load_email(is_spam=False , filename=name) for name in ham_filenames ]\n",
    "spam_emails = [load_email(is_spam = True , filename=name) for name in spam_filenames]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "8e8be867",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<email.message.EmailMessage object at 0x0000022C85B14B00>, <email.message.EmailMessage object at 0x0000022C85B14D10>, <email.message.EmailMessage object at 0x0000022C85B14E60>, <email.message.EmailMessage object at 0x0000022C85B15C70>, <email.message.EmailMessage object at 0x0000022C85B15580>]\n"
     ]
    }
   ],
   "source": [
    "print(ham_emails[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "9f44851d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_email_structure(email):\n",
    "    if isinstance(email , str): \n",
    "        return email\n",
    "    payload = email.get_payload() #Here if the email is multipart then it will contain contain content of each subpart\n",
    "    if isinstance(payload, list):\n",
    "        return \"multipart({})\".format(\",\".join([get_email_structure(sub_email) for sub_email in payload]))\n",
    "    else:\n",
    "        return email.get_content_type()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "d56187fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "def structures_counter(emails):\n",
    "    structures = Counter() \n",
    "    for email in emails:\n",
    "        structure = get_email_structure(email)\n",
    "        structures[structure] += 1  \n",
    "    return structures  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "ffb63959",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('text/plain', 218),\n",
       " ('text/html', 183),\n",
       " ('multipart(text/plain,text/html)', 45),\n",
       " ('multipart(text/html)', 20),\n",
       " ('multipart(text/plain)', 19),\n",
       " ('multipart(multipart(text/html))', 5),\n",
       " ('multipart(text/plain,image/jpeg)', 3),\n",
       " ('multipart(text/html,application/octet-stream)', 2),\n",
       " ('multipart(text/plain,application/octet-stream)', 1),\n",
       " ('multipart(text/html,text/plain)', 1),\n",
       " ('multipart(multipart(text/html),application/octet-stream,image/jpeg)', 1),\n",
       " ('multipart(multipart(text/plain,text/html),image/gif)', 1),\n",
       " ('multipart/alternative', 1)]"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "structures_counter(ham_emails).most_common()\n",
    "structures_counter(spam_emails).most_common()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "dba28f1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X = ham_emails + spam_emails\n",
    "Y = np.array([0] * len(ham_emails) + [1] * len(spam_emails))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "5b255c58",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train , x_test , y_train , y_test = train_test_split(X , Y , test_size= 0.2 , random_state= 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "7bceb8d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup #esley chahi string accept garcha hai \n",
    "from html import unescape\n",
    "\n",
    "def html_to_plain_text(html):  #This accepts only string\n",
    "\n",
    "    soup = BeautifulSoup(html , 'lxml')\n",
    "\n",
    "    if soup.head: #Esley Head remove garcha\n",
    "        soup.head.decompose()\n",
    "\n",
    "\n",
    "    for a in soup.find_all(\"a\"): #This replaces all the <a> tags with Hyperlink\n",
    "        a.replace_with(\" HYPERLINK \")\n",
    "\n",
    "\n",
    "    for tags in soup.find_all():\n",
    "        if tags.name == \"a\":\n",
    "            continue\n",
    "        if tags.name == \"head\":\n",
    "            continue\n",
    "        if tags.string:\n",
    "            continue\n",
    "        tags.unwrap()\n",
    "\n",
    "    text = soup.get_text()\n",
    "\n",
    "    return unescape(text.strip())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "99e64e9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def email_to_text(msg): #Converts the html of the email object into the strings\n",
    "    for part in msg.walk(): #Iterates through multiple parts of the email\n",
    "        content_type = part.get_content_type() \n",
    "\n",
    "        if content_type == \"text/html\":\n",
    "            return part.get_payload(decode = True).decode(errors =\"ignore\")\n",
    "        \n",
    "        if content_type == \"text/plain\":\n",
    "            text = part.get_payload(deocde = True)\n",
    "            if text:\n",
    "                return text.decode(errors = \"ignore\")\n",
    "    return \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "c9374158",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_spam_email = [email for email , label in zip(x_train , y_train) \n",
    "                     if label == 1 and get_email_structure(email) == 'text/html']\n",
    "sample_spam_email_1 = sample_spam_email[7] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "a715a11f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OTC\n",
      "\n",
      " Newsletter\n",
      "Discover Tomorrow's Winners \n",
      "\n",
      "For Immediate Release\n",
      "\n",
      "Cal-Bay (Stock Symbol: CBYI)\n",
      "Watch for analyst \"Strong Buy Recommendations\" and several advisory newsletters picking CBYI.  CBYI has filed to be traded on the OTCBB, share prices historically INCREASE when companies get listed on this larger trading exchange. CBYI is trading around 25 cents and should skyrocket to $2.66 - $3.25 a share in the near future.\n",
      "Put CBYI on your watch list, acquire a position TODAY.\n",
      "\n",
      "REASONS TO INVEST IN CBYI\n",
      "\n",
      "A profitable company and is on track to beat ALL earnings estimates!\n",
      "\n",
      "One of the FASTEST growing distributors in environmental & safety equipment instruments.\n",
      "\n",
      "Excellent management team, several EXCLUSIVE contracts.  IMPRESSIVE client list including the U.S. Air Force, Anheuser-Busch, Chevron Refining and Mitsubishi Heavy Industries, GE-Energy & Environmental Research.\n",
      "\n",
      "RAPIDLY GROWING INDUSTRY\n",
      "Industry revenues exceed $900 million, estimates indicate that there could be as much as $25 billion from \"smell technology\" by the end of 2003.\n",
      "\n",
      "!!!!!CONGRATULATIONS!!!!!Our last recommendation to buy ORBT at $1.29 rallied and is holding steady at $3.50! Congratulations to all our subscribers that took advantage of this recommendation.\n",
      "\n",
      "ALL removes HONORED. Please allow 7 days to be removed and send ALL addresses to:\n",
      "\n",
      " HYPERLINK  \n",
      "\n",
      "Certain statements contained in this news release may be forward-looking statements within the meaning of The Private Securities Litigation Reform Act of 1995. These statements may be identified by such terms as \"expect\", \"believe\", \"may\", \"will\", and \"intend\" or similar terms. We are NOT a registered investment advisor or a broker dealer. This is NOT an offer to buy or sell securities. No recommendation that the securities of the companies profiled should be purchased, sold or held by individuals or entities that learn of the profiled companies. We were paid $27,000 in cash by a third party to publish this report. Investing in companies profiled is high-risk and use of this information is for reading purposes only. If anyone decides to act as an investor, then it will be that investor's sole risk. Investors are advised NOT to invest without the proper advisement from an attorney or a registered financial broker. Do not rely solely on the information presented, do additional independent research to form your own opinion and decision regarding investing in the profiled companies. Be advised that the purchase of such high-risk securities may result in the loss of your entire investment.  Not intended for recipients or residents of CA,CO,CT,DE,ID, IL,IA,LA,MO,NV,NC,OK,OH,PA,RI,TN,VA,WA,WV,WI. Void where prohibited.  The owners of this publication may already own free trading shares in CBYI and may immediately sell all or a portion of these shares into the open market at or about the time this report is published.  Factual statements are made as of the date stated and are subject to change without notice.\n",
      "Copyright c 2001\n",
      "≡\n",
      "\n",
      "OTC\n",
      "≡\n",
      "\n",
      "***\n"
     ]
    }
   ],
   "source": [
    "raw = email_to_text(sample_spam_email_1)\n",
    "print(html_to_plain_text(raw))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e4a1184e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import urlextract\n",
    "import nltk\n",
    "url = urlextract.URLExtract()\n",
    "stemmer = nltk.PorterStemmer()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "756c7e47",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator , TransformerMixin\n",
    "\n",
    "class email_to_word_count(BaseEstimator , TransformerMixin):\n",
    "    def __init__(self , strip_headers = True , lower_case = True , \n",
    "                 url_replace = True , stemming = True ,  replace_numbers = True ):\n",
    "        self.strip_headers = strip_headers\n",
    "        self.lower_case = lower_case\n",
    "        self.url_replace = url_replace\n",
    "        self.stemming = stemming \n",
    "        self.replace_numbers = replace_numbers\n",
    "    def fit( self  , x , y=None):\n",
    "        return self\n",
    "    def transform(self , x , y=None):\n",
    "        X_transformed = []\n",
    "        for email in X:\n",
    "            text = email_to_text(email) or \"\"\n",
    "            if self.lower_case:\n",
    "                text = text.lower()\n",
    "            if self.url_replace and url is not None:\n",
    "                url_1 = list(set(url.find_urls(text)))\n",
    "                url_1.sort(key = lambda url : len(url) , reverse=True)\n",
    "                for url in url_1:\n",
    "                    print(url , \"url\")\n",
    "            if self.replace_numbers:\n",
    "                words = text.split()\n",
    "                new_word = []\n",
    "                for word in words:\n",
    "                    try:\n",
    "                        float(word)\n",
    "                        new_word.append(\"NUMBER\")\n",
    "                    except ValueError:\n",
    "                        new_word.append(word)\n",
    "                text = \"\" .join(new_word)\n",
    "            counter = Counter(text.split())\n",
    "            if self.stemming and stemmer is not None:\n",
    "                stemmed_word_counts = Counter()\n",
    "                for word , count in counter.items():\n",
    "                    stemmed_word = stemmer.stem(word)\n",
    "                    stemmed_word_counts[stemmed_word] += count\n",
    "                counter = stemmed_word_counts\n",
    "\n",
    "            X_transformed.append(counter)\n",
    "        return np.array(X_transformed)\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
